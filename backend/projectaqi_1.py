# -*- coding: utf-8 -*-
"""ProjectAQI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hhg74RMMDYeMim-6oLjLAcn3gDU9ieNh
"""



import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

from sklearn.preprocessing import StandardScaler

data=pd.read_csv("/content/aqi_up.csv")
data

data.info()

data.columns = data.columns.str.strip().str.lower()


for col in ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']:
    if col in data.columns:
        data[col] = (
            data[col]
            .astype(str)
            .str.extract(r'([\d\.]+)')[0]
            .astype(float)
        )
data['date'] = pd.to_datetime(data['date'],format='mixed')

data.info()

data.describe()

data.isna().sum()

data['city'].unique()

data['day'] = data['date'].dt.day
data['month'] = data['date'].dt.month
data['year'] = data['date'].dt.year

year_counts = data['year'].value_counts().sort_index()



data = data[data['year'] > 2018]

year_counts = data['year'].value_counts().sort_index()

year_counts.plot(kind='bar', title='Data Entries per Year')
plt.xlabel('Year')
plt.ylabel('Number of Rows')
plt.tight_layout()
plt.show()



data['year'].value_counts().sort_index()

city_counts = data['city'].value_counts()
plt.pie(city_counts, labels=city_counts.index, autopct='%1.1f%%', shadow=True)
plt.title('City Distribution')
plt.axis('equal')  #
plt.show()
print(city_counts)

"""sns.scatterplot(x='city', y='pm10', data=data,hue='pm10')
plt.xticks(rotation =90)

sns.scatterplot(x='city', y='pm25', data=data,hue='pm25')
plt.xticks(rotation =90)
"""
#sns.pairplot(hue="city",data=data)

for col in['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']:
   for city in data['city'].unique():
      med_val = data[data['city'] == city][col].median()
      data.loc[
          (data['city'] == city) & (data[col].isnull()),
          col
      ] = med_val

data.isna().sum()

"""sns.histplot(data= data[data["city"] == "thiruvananthapuram"], x="pm25", kde=True)
plt.title("Distribution of PM25 in Thiruvananthapuram")
plt.xlabel("PM25")
plt.ylabel("Frequency")
plt.show()

plt.figure(figsize=(8,6))
sns.boxplot(data)
plt.title("Boxplot")
plt.show()"""

"""cols = ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']
for col in cols:
  plt.figure(figsize=(12, 6))
  sns.boxplot(x='city', y=col, data=data)
  plt.title(f"{col} by City")
  plt.xticks(rotation=90)
  plt.show()"""

cols = ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']

for col in cols:
    for city in data['city'].unique():
        city_data = data[data['city'] == city][col]

        Q1 = city_data.quantile(0.25)
        Q3 = city_data.quantile(0.75)
        IQR = Q3 - Q1

        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        data.loc[data['city'] == city, col] = city_data.clip(lower_bound, upper_bound)

cols = ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']
for col in cols:
  plt.figure(figsize=(12, 6))
  sns.boxplot(x='city', y=col, data=data)
  plt.title(f"{col} by each City")
  plt.xticks(rotation=90)
  plt.show()

data

data.drop_duplicates(inplace=True)

data







breakpoints = {
    'pm25': [
        (0, 30, 0, 50), (31, 60, 51, 100), (61, 90, 101, 200),
        (91, 120, 201, 300), (121, 250, 301, 400), (251, 350, 401, 500)
    ],
    'pm10': [
        (0, 50, 0, 50), (51, 100, 51, 100), (101, 250, 101, 200),
        (251, 350, 201, 300), (351, 430, 301, 400), (431, 500, 401, 500)
    ],
    'o3': [
        (0, 50, 0, 50), (51, 100, 51, 100), (101, 168, 101, 200),
        (169, 208, 201, 300), (209, 748, 301, 400), (749, 1000, 401, 500)
    ],
    'no2': [
        (0, 40, 0, 50), (41, 80, 51, 100), (81, 180, 101, 200),
        (181, 280, 201, 300), (281, 400, 301, 400), (401, 500, 401, 500)
    ],
    'so2': [
        (0, 40, 0, 50), (41, 80, 51, 100), (81, 380, 101, 200),
        (381, 800, 201, 300), (801, 1600, 301, 400), (1601, 2000, 401, 500)
    ],
    'co': [
        (0, 1, 0, 50), (1.1, 2, 51, 100), (2.1, 10, 101, 200),
        (10.1, 17, 201, 300), (17.1, 34, 301, 400), (34.1, 50, 401, 500)
    ]
}

def calc_subindex(pollutant, value):
    for bp_low, bp_high, index_low, index_high in breakpoints[pollutant]:
        if bp_low <= value <= bp_high:
            aqi= ((index_high - index_low) / (bp_high - bp_low)) * (value - bp_low) + index_low
            print("val",aqi)
            return aqi
    return None

aqi_values = []
aqi_pollutant = []
for i, row in data.iterrows():
    sub_indices = {}
    for pollutant in ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co']:
        if pollutant in row and pd.notna(row[pollutant]):
            value = row[pollutant]
            print(f"{pollutant}: {value}")
            sub_index = calc_subindex(pollutant, value)
            if sub_index is not None:
                sub_indices[pollutant] = round(sub_index)
    aqi = max(sub_indices.values()) if sub_indices else None
    aqi_gas = max(sub_indices, key=sub_indices.get) if sub_indices else None
    print(f"{max(sub_indices.values()) if sub_indices else None}: {aqi}")
    aqi_values.append(aqi)
    aqi_pollutant.append(aqi_gas)


data["aqi"] = aqi_values
data["pollutant"] = aqi_pollutant

#data["AQI"] = data.apply(calculate_aqi, axis=1)


print("✅ AQI calculated and saved to aqi_output.csv")

data

sns.scatterplot(x='city', y='aqi', data=data,hue='aqi')
plt.xticks(rotation =90)
plt.axhline(100, color='green', linestyle='--', label='Moderate')
plt.axhline(200, color='orange', linestyle='--', label='Unhealthy')
plt.legend()





"""plt.plot(data['city'== 'thiruvananthapuram'],data['aqi'],"g,--",marker='o')
plt.xticks(ticks= range(1, 25,1),rotation =45)
plt.title("Model Accuracy vs K Value")
plt.xlabel("K value")
plt.ylabel("Accuracy")
plt.grid()
plt.show()"""

plt.figure(figsize=(10, 6))
sns.histplot(data['aqi'], bins=50, kde=True)
plt.title('Distribution of AQI Values')
plt.xlabel('AQI')
plt.ylabel('Frequency')
plt.show()

cols =data['city'].unique()
for col in cols:

  sns.histplot(x='aqi', data=data[data['city'] == col] ,kde=True)
  plt.title(f"Distribution of AQI Values by {col} City")
  plt.xticks(rotation=90)
  plt.show()

def get_aqi_category(aqi):
    if pd.isna(aqi):
        return np.nan
    elif aqi <= 50:
        return 'Good'
    elif aqi <= 100:
        return 'Moderate'
    elif aqi <= 150:
        return 'Unhealthy for Sensitive Groups'
    elif aqi <= 200:
        return 'Unhealthy'
    elif aqi <= 300:
        return 'Very Unhealthy'
    else:
        return 'Hazardous'

data

#data["aqi_category"].value_counts()

data.info()

data

from sklearn.preprocessing import StandardScaler

scale_cols = ['pm25', 'pm10', 'o3', 'no2', 'so2', 'co', 'day', 'month', 'year']
sd = StandardScaler()
data_sc = data.copy()
data_sc[scale_cols] = sd.fit_transform(data[scale_cols])

#x['city'] = LabelEncoder().fit_transform(x['city'])

from prophet import Prophet

data

df_city = data[data['city'] == 'delhi'][['date', 'aqi']].copy()
df_city = df_city.rename(columns={'date': 'ds', 'aqi': 'y'})
df_city

df_city = df_city.set_index('ds').asfreq('D')
df_city['y'] = df_city['y'].interpolate()
df_city = df_city.reset_index()
df_city



model = Prophet()
model.fit(df_city)

model = Prophet()

model.fit(df_city)

future = model.make_future_dataframe(periods=30)

# Predict
forecast = model.predict(future)

# Plot
model.plot(forecast)

forecast

aqid = forecast[forecast['ds'] == '2025-08-20']
aqid

user_input = input("Enter a date (YYYY-MM-DD): ")
input_date = pd.to_datetime(user_input)

# --- Step 4: Look up prediction for that date ---
result = forecast[forecast['ds'] == input_date]

data

city_input = input("Enter city name: ").strip()
date_input = input("Enter date to predict (YYYY-MM-DD): ").strip()


df_city = data[data['city'].str.lower() == city_input.lower()][['date', 'aqi']].copy()
df_city = df_city.rename(columns={'date': 'ds', 'aqi': 'y'})
df_city = df_city.set_index('ds').asfreq('D')
df_city['y'] = df_city['y'].interpolate()
df_city = df_city.reset_index()
model = Prophet()
model.fit(df_city)

future = model.make_future_dataframe(periods=365)
forecast = model.predict(future)


target = forecast[forecast['ds'] == pd.to_datetime(date_input)]
print(target,"this s")
if not target.empty:
  predicted_aqi = round(target['yhat'].values[0], 2)
  get_aqi_category(predicted_aqi)


  print(f"\n📍 Predicted AQI for {city_input.title()} on {date_input}: {predicted_aqi}")
  print(f"🧾 AQI Category: {get_aqi_category(predicted_aqi)}")
else:
  print("⚠️ Date out of range or invalid. Try a date within ~30–60 days from the last available data.")

# prompt: use pickle instead of joblib and train model again for all the cities .

import pandas as pd
import pickle
import os

# Directory to save models
model_dir = 'prophet_models'
os.makedirs(model_dir, exist_ok=True)

city_forecasts = {}

for city in data['city'].unique():
    print(f"Training model for {city}")
    df_city = data[data['city'] == city][['date', 'aqi']].copy()
    df_city = df_city.rename(columns={'date': 'ds', 'aqi': 'y'})
    df_city = df_city.set_index('ds').asfreq('D')
    df_city['y'] = df_city['y'].interpolate()
    df_city = df_city.reset_index()

    if not df_city.empty:
        model = Prophet()
        model.fit(df_city)

        # Save the trained model using pickle
        model_filename = os.path.join(model_dir, f'prophet_model_{city.replace(" ", "_")}.pkl')
        with open(model_filename, 'wb') as f:
            pickle.dump(model, f)

        print(f"Model for {city} saved to {model_filename}")

        # Generate and store forecast
        future = model.make_future_dataframe(periods=365) # Adjust periods as needed
        forecast = model.predict(future)
        city_forecasts[city] = forecast
    else:
        print(f"No data available for {city}, skipping model training.")

print("\nTraining complete for all cities.")

# Example of loading a model and making a prediction
city_to_predict = input("Enter city name to predict for: ").strip()
date_to_predict = input("Enter date to predict (YYYY-MM-DD): ").strip()

model_filename_to_load = os.path.join(model_dir, f'prophet_model_{city_to_predict.replace(" ", "_")}.pkl')

if os.path.exists(model_filename_to_load):
    with open(model_filename_to_load, 'rb') as f:
        loaded_model = pickle.load(f)

    # If you already generated forecasts above, you can use them
    if city_to_predict in city_forecasts:
        forecast = city_forecasts[city_to_predict]
    else:
        # If you didn't generate forecasts above, make one now
        df_city = data[data['city'] == city_to_predict][['date', 'aqi']].copy()
        df_city = df_city.rename(columns={'date': 'ds', 'aqi': 'y'})
        df_city = df_city.set_index('ds').asfreq('D')
        df_city['y'] = df_city['y'].interpolate()
        df_city = df_city.reset_index()
        future = loaded_model.make_future_dataframe(periods=365) # Adjust periods as needed
        forecast = loaded_model.predict(future)

    target = forecast[forecast['ds'] == pd.to_datetime(date_to_predict)]

    if not target.empty:
        predicted_aqi = round(target['yhat'].values[0], 2)
        print(f"\n📍 Predicted AQI for {city_to_predict.title()} on {date_to_predict}: {predicted_aqi}")
        print(f"🧾 AQI Category: {get_aqi_category(predicted_aqi)}")
    else:
        print("⚠️ Date out of range or invalid.")
else:
    print(f"⚠️ No trained model found for {city_to_predict}.")



from sklearn.metrics import mean_squared_error, mean_absolute_error
from math import sqrt
from sklearn.model_selection import train_test_split


def evaluate_prophet_model(model, df_train, df_test):
    """Evaluates a trained Prophet model on a test set."""
    future_test = model.make_future_dataframe(periods=len(df_test), include_history=False)
    forecast_test = model.predict(future_test)


    actual = df_test['y'].values
    predicted = forecast_test['yhat'].values


    rmse = sqrt(mean_squared_error(actual, predicted))
    mae = mean_absolute_error(actual, predicted)

    print(f'  RMSE: {rmse:.2f}')
    print(f'  MAE: {mae:.2f}')


print("\n--- Model Evaluation ---")
for city in data['city'].unique():
    print(f"\nEvaluating model for {city}...")


    model_filename = f"/content/prophet_models/prophet_model_{city.replace(' ', '_').lower()}.pkl"
    try:
        model = joblib.load(model_filename)
    except FileNotFoundError:
        print(f"  Model file not found for {city}. Skipping evaluation.")
        continue

    df_city = data[data['city'].str.lower() == city.lower()][['date', 'aqi']].copy()
    df_city = df_city.rename(columns={'date': 'ds', 'aqi': 'y'})
    df_city = df_city.set_index('ds').asfreq('D')
    df_city['y'] = df_city['y'].interpolate()
    df_city = df_city.reset_index()

    if len(df_city) < 2:
        print(f"  Not enough data for {city}. Skipping evaluation.")
        continue


    train_size = int(len(df_city) * 0.8)
    df_train = df_city[:train_size]
    df_test = df_city[train_size:]

    if len(df_test) == 0:
        print(f"  Not enough data for {city} to create a test set. Skipping evaluation.")
        continue



    evaluate_prophet_model(model, df_train, df_test)

